# Mineru2Questions 项目评审报告 (v1.4)

**致**：项目总设计师与技术总监
**发件人**：Manus AI (独立测试部门)
**日期**：2026年02月09日
**主题**：关于 Commit `6517d92` 的回归测试与根因分析

## 1. 评审摘要 (Executive Summary)

本次评审旨在对 `Mineru2Questions` 项目最新提交 (`6517d92`) 进行回归测试，核心是验证 v1.3 报告中指出的两个 P0 级缺陷是否已成功修复。测试任务 `202602091753-1770630795175` 的结果显示，**修复未能完全成功，核心产出依然为 0 道题目**。

**根因分析定位到一个新的、此前被掩盖的 P0 级缺陷**：

- **API 调用超时单位错误**：在 `taskProcessor.ts` 和 `extraction.ts` 中，从数据库读取的 `timeout` 值（单位：秒）被直接传递给了 `axios`，而 `axios` 的 `timeout` 参数期望的是**毫秒**。这导致 API 调用超时被错误地设置为 300 毫秒（0.3秒），所有对大模型的调用都因瞬间超时而失败，造成了任务在 1 秒内“成功”结束却无任何产出的假象。

**好消息是**，v1.3 报告中指出的两个 P0 缺陷已在代码层面得到确认修复：

1.  **API 端点调用错误**：已修复。代码现在能正确拼接 `/chat/completions` 路径。
2.  **任务目录路径解析错误**：已修复。`debug` 和 `results` 目录现在能正确生成在每个任务的独立子目录下。

然而，由于新发现的 `timeout` 单位错误，API 调用在网络层面就被中断，导致了与上次同样“静默失败”的最终结果。本报告将详细阐述这一新缺陷的分析过程，并提供精准的代码修复建议。

## 2. 根因分析：为何修复后依然输出 0 题？

对测试任务 `202602091753-1770630795175` 的分析显示，尽管路径和 API 端点问题已解决，但任务执行的核心症状并未改变：**极短的执行时间**和**缺失的日志**。

### 2.1. 现象：1秒“完成”的任务

数据库日志再次提供了关键线索：

> - **任务 26 (本次测试)**: 处理 3 个数据块 (chunks)，耗时 **1 秒**，产出 0 题。
> - **任务 25 (上次测试)**: 处理 16 个数据块，耗时 **3 秒**，产出 0 题。
> - **任务 23 (历史成功任务)**: 处理相似数据，耗时 **14.5 分钟**，产出 575 题。

任务执行时间从 3 秒缩短到 1 秒，与 chunk 数量从 16 个减少到 3 个完全成正比。这强烈暗示**每个 chunk 的处理都在一个极短的、固定的时间内失败**。同时，`logs` 目录依然没有被创建，说明错误发生在 `callLLM` 函数内部，且在 `fs.writeFileSync` 保存 LLM 输出之前。

### 2.2. 缺陷：超时单位不匹配 (P0级)

在确认 API 端点拼接正确后，我们将审查重点放在了 API 调用的参数上，特别是 `timeout`。通过追溯 `timeout` 值的传递路径，我们发现了这个致命缺陷：

1.  **数据库 (`llm_configs` 表)**: `timeout` 字段存储的值为 `300`，其业务含义是 **300 秒**。
2.  **`taskProcessor.ts` (L81)**: 代码 `timeout: llmConfig.timeout || 60000` 将数据库中的 `300` 直接传递下去。
3.  **`extraction.ts` (L355)**: `axios` 配置接收到 `timeout: 300`。
4.  **`axios` 库的行为**: `axios` 的 `timeout` 配置项单位是**毫秒**。

因此，一个意图为 5 分钟 (300 秒) 的超时，被错误地设置为 **300 毫秒**。对于任何一个需要数秒乃至数十秒才能完成的大模型调用来说，这都会导致请求立即因 `ECONNABORTED` (连接中止) 或类似的超时错误而失败。

这个错误完美地解释了所有观察到的现象：

- **执行时间极短**：每个 chunk 的 API 调用都在约 0.3 秒后失败，所以总时间约等于 `chunk数量 * 0.3s`。
- **无 `logs` 目录**：`axios` 抛出超时异常，被 `catch` 块捕获。`catch` 块中的日志增强代码虽然被执行，但由于 `tsx watch` 可能没有重新加载最新的 `extraction.ts` 文件，或者存在其他运行时问题，导致增强的日志逻辑并未生效，`logs` 目录未能创建。

通过对比历史成功版本 (`d345d6d`) 的代码，我们确认旧版实现中有明确的单位转换逻辑，进一步证实了这是一个在近期重构中引入的**严重回归缺陷**。

```typescript
// 历史正确实现 (e.g., commit d345d6d)
const effectiveTimeout = Math.max(config.timeout || 120, 120) * 1000; // 明确乘以 1000
```

## 3. 与 DataFlow 官方流水线对齐复查

关于 `timeout` 的处理，我们对 `OpenDCAI/DataFlow` 官方仓库进行了复查。在其 `dataflow/serving/api_vlm_serving_openai.py` 模块中，`OpenAI` 客户端的 `timeout` 参数直接接收一个以**秒**为单位的整数，默认值为 `1800`。

```python
# DataFlow 官方实现
class APIVLMServing_openai(LLMServingABC):
    def __init__(self, ..., timeout: int = 1800, ...):
        self.timeout = timeout
        ...
        self.client = OpenAI(..., timeout=self.timeout) # openai-python v1+ 库接收秒
```

这说明，虽然官方流水线也使用以“秒”为单位的配置，但其底层的 `openai-python` 库和本项目使用的 `axios` 库在 `timeout` 参数的单位约定上是**不一致的**。`axios` 需要毫秒，而 `openai-python` v1.x+ 需要秒。因此，在本项目中进行单位转换是**必须的、正确的**操作。

## 4. 修订建议

为彻底解决此问题，现提出以下**唯一且必须执行的 P0 级修复建议**：

1.  **修复超时单位**：在 `server/taskProcessor.ts` 中，从数据库获取配置并传递给核心提取函数时，进行正确的单位转换。

    ```typescript
    // 文件: server/taskProcessor.ts
    // 修正建议 (line 81)
    const config: LLMConfig = {
      apiUrl: llmConfig.apiUrl,
      apiKey: llmConfig.apiKey,
      modelName: llmConfig.modelName,
      // 核心修复：将数据库中的秒转换为 axios 需要的毫秒
      timeout: (llmConfig.timeout || 60) * 1000, 
      maxRetries: 3
    };
    ```

    **理由**：在数据流入核心逻辑 (`extraction.ts`) 之前，在 `taskProcessor.ts` 的适配层完成单位转换，是更清晰、更符合分层设计原则的做法。这能确保 `extractQuestions` 函数接收到的 `config` 对象内部单位一致，无需关心数据来源。

2.  **验证编译与部署流程**：在应用此修复后，**必须确保 TypeScript 代码被重新编译，并且运行中的 Node.js 服务 (通过 `tsx watch`) 已加载了最新的代码**。建议在启动服务前执行一次 `pnpm build`，或在 `dev` 脚本中确保 `tsx` 能可靠地检测到文件变更并重启服务。

## 5. 结论

本次回归测试成功地将问题范围缩小到了一个**单一、明确的 `timeout` 单位错误**。尽管上次报告中指出的两个 P0 缺陷在代码层面已修复，但由于此新发现的缺陷，导致了同样的失败结果。

**一旦上述 P0 级 `timeout` 单位转换问题得到修复，并确保运行环境加载了最新代码，项目应能恢复正常的题目提取能力。**

独立测试部门建议立即执行此修复，并再次提交进行回归测试。届时，我们将重点验证任务执行时间是否恢复到分钟级别，以及 `results` 和 `logs` 目录中是否出现预期的产出文件。
