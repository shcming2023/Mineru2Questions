# 产品需求文档 (PRD): Mineru2Questions

**版本**: 1.1
**修订日期**: 2026-02-09
**负责人**: Manus AI

---

## 1. 背景与战略调整

### 1.1 修订背景

在完成对 v1.0 版本的技术评审后，我们发现，尽管项目在对齐 OpenDCAI/DataFlow 官方流水线方面基础扎实（架构对齐度 92.5%），但在处理真实世界中常见的“题解分离”文档时，其功能完整性（62.0%）和容错机制（37.5%）存在严重不足。特别是，“远距离答案匹配”这一功能不仅实现复杂度高，且在当前阶段严重拖累了项目的开发进度和稳定性。

### 1.2 战略决策：聚焦核心价值，快速迭代

为了以最快速度交付核心价值并提升系统鲁棒性，我们做出以下战略调整：

> **核心决策：暂时舍弃复杂的“远距离答案匹配”功能，将产品核心聚焦于“高质量、结构化题目提取”，同时保留对“近距离图文例题”的解析能力。**

本次 PRD 修订旨在明确新的产品边界，对齐当前开发进度，并为下一阶段的开发工作提供清晰、可执行的指引。

### 1.3 产品定位

**产品名称**: Mineru2Questions - 高质量题目提取引擎

**产品愿景**: 成为教育内容领域最精准、最鲁棒的结构化题目提取服务，将非结构化的 PDF 教材、讲义、试卷，高效转化为可用于下游应用（如智能题库、学习分析、AI 助教）的高质量数据资产。

**目标用户**:

| 用户角色 | 核心需求 |
| :--- | :--- |
| **教育内容提供商** | 从海量 PDF 教辅资料中批量构建结构化、可检索的数字题库。 |
| **在线教育平台** | 为其平台快速扩充题目资源，支持题目推荐、智能组卷等功能。 |
| **教师与教研人员** | 高效整理教材或讲义中的题目和例题，用于备课和教学。 |

---

## 2. 功能范围与边界 (Scope)

### 2.1 核心功能 (In-Scope)

| 功能模块 | 需求描述 | 验收标准 (AC) |
| :--- | :--- | :--- |
| **1. 高质量题目提取** | 必须完整提取题目的所有组成部分，包括题干、选项、图片和公式，确保语义和结构的完整性。 | AC-1.1: 题目文本与 `content_list.json` 中的原文完全一致。<br>AC-1.2: 题目中包含的所有图片、公式 Block 必须被正确识别并包含在 ID 序列中。 |
| **2. 结构化元数据提取** | 必须为每道题目提取准确的元数据，用于分类和检索。 | AC-2.1: 必须提取 `chapter_title`、`label` (题号)、`page_idx` (页码)。<br>AC-2.2: 必须根据题号标签（如“例1”、“习题3”）自动区分为 `type: "example"` 或 `type: "exercise"`。 |
| **3. 近距离答案提取** | **仅针对 `type: "example"` 的题目**，提取其紧随其后的答案和解题步骤。 | AC-3.1: “近距离”定义为题目结束后的 50 个 block 内。<br>AC-3.2: 能够识别“解：”、“答：”、“解析：”等显式答案标识。<br>AC-3.3: 若在范围内未找到答案，`answer` 和 `solution` 字段应为空，`has_answer` 标记为 `false`。 |
| **4. 系统鲁棒性与可观测性** | 流水线必须具备容错能力和足以支持问题诊断的日志。 | AC-4.1: 当 LLM 输出格式错误时，系统应有回退机制（如宽松解析），而不是中断任务。<br>AC-4.2: **必须**将每个处理块（chunk）的 LLM 原始输出和解析后结果保存到独立的日志文件中。 |

### 2.2 明确不支持的场景 (Out-of-Scope)

为确保项目聚焦，以下功能在 v1.1 版本中 **明确不予支持**：

- ❌ **远距离答案匹配**: 不支持匹配位于章节末尾或书本末尾的集中答案区域。
- ❌ **答案区域自动检测**: 移除 `DEFAULT_ANSWER_DETECTION` 逻辑，不再对文档进行“题目区”和“答案区”的宏观划分。
- ❌ **跨文档问答合并**: 不支持从一个文档提取问题，从另一个文档提取答案进行合并的场景。

---

## 3. 技术方案与数据结构

### 3.1 简化的技术流水线

为对齐新的产品策略，原有的技术流水线将进行简化，移除不必要的复杂性。

**v1.1 精简流水线**:

1.  **Input Formatting**: 加载 `content_list.json`，为每个 block 分配 ID，展平列表并过滤页眉、页脚等噪音。
2.  **LLM Extraction**: **单次调用 LLM**。使用聚焦题目提取的简化版提示词，对格式化的 block 进行分块处理。
3.  **Output Parsing**: 解析 LLM 的 XML 输出。严格执行 ID-Only 原则，通过 ID 回填文本和图片路径。**此阶段集成格式错误的回退逻辑**。
4.  **Post-Processing & Enrichment**: 
    -   根据 `label` 字段识别题目 `type`。
    -   **仅对 `type: "example"` 的题目**，执行“近距离答案检测”逻辑。
5.  **Quality Filtering & Output**: 过滤掉缺少题干或关键信息的低质量数据，然后按指定格式输出。

### 3.2 移除的模块

- `server/qa-merger.ts`: 问答对合并算子不再需要，应予移除或标记为废弃。
- `detectAnswerSection` 相关逻辑：从主流程中彻底移除。

### 3.3 最终输出数据结构 (JSON Schema)

```json
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "Extracted Question",
  "type": "object",
  "properties": {
    "label": {
      "description": "原始题号，如 ‘1’、‘例2’。",
      "type": "string"
    },
    "type": {
      "description": "题目类型，根据标签自动判断。",
      "enum": ["exercise", "example"]
    },
    "chapter_title": {
      "description": "题目所属的章节标题。",
      "type": "string"
    },
    "question": {
      "description": "完整的题目文本，包含所有文字内容。",
      "type": "string"
    },
    "answer": {
      "description": "最终答案，通常为短文本。仅对 type 为 ‘example’ 的题目提取。",
      "type": "string"
    },
    "solution": {
      "description": "详细的解题步骤。仅对 type 为 ‘example’ 的题目提取。",
      "type": "string"
    },
    "images": {
      "description": "题目中包含的所有图片的相对路径列表。",
      "type": "array",
      "items": { "type": "string" }
    },
    "page_idx": {
      "description": "题目起始内容所在的页码（从0开始）。",
      "type": "integer"
    },
    "has_answer": {
      "description": "一个布尔标记，指示是否成功提取到答案或解题步骤。",
      "type": "boolean"
    }
  },
  "required": ["label", "type", "chapter_title", "question", "images", "page_idx", "has_answer"]
}
```

---

## 4. 下一阶段开发路线图 (Roadmap)

### 4.1 阶段一：核心功能稳定 (预计 2 周)

**目标**: 实现 P0 级改进，确保题目提取的稳定性和完整性，达到可交付的最小化产品（MVP）状态。

| 优先级 | 任务 (User Story) | 验收标准 |
| :--- | :--- | :--- |
| **P0.1** | **强化图片提取**: 作为内容开发者，我希望题目中的图片能被完整提取，因为图片是题目的核心部分。 | 图片提取的召回率 > 90%；图文混排的题目文本连续、无断裂。 |
| **P0.2** | **实现容错回退**: 作为系统维护者，我希望单个解析错误不会导致整个任务失败，以保证系统的稳定性。 | 实现 `lenientParse` 模式；单个 chunk 失败后，任务能继续执行。 |
| **P0.3** | **实现诊断日志**: 作为开发者，我需要查看 LLM 的原始输出，以便快速诊断和修复问题。 | 每个 chunk 的 LLM 原始输出和解析结果都被保存到独立的日志文件。 |
| **P0.4** | **优化章节标题提取**: 作为用户，我希望题目的章节信息是准确的，以便于组织和检索。 | 章节标题的提取准确率 > 85%；不再出现 ID 回填错误的异常标题。 |

### 4.2 阶段二：例题答案支持 (预计 1 周)

**目标**: 在稳定的题目提取基础上，增加对“近距离例题”的答案解析能力，提升产品价值。

| 优先级 | 任务 (User Story) | 验收标准 |
| :--- | :--- | :--- |
| **P1.1** | **实现题目类型识别**: 作为用户，我希望系统能自动区分“练习题”和“例题”。 | `label` 中包含“例”或“example”的题目 `type` 字段被正确标记为 `example`，准确率 > 95%。 |
| **P1.2** | **提取近距离答案**: 作为教师，我希望查看例题时能直接看到其紧随的答案和解析。 | 对 `type: "example"` 的题目，其 50 个 block 内的答案和解析召回率 > 80%。 |

### 4.3 阶段三：质量优化与文档完善 (预计 1 周)

**目标**: 提升代码质量、完善项目文档，为后续的开源或商业化交付做准备。

| 优先级 | 任务 (User Story) | 验收标准 |
| :--- | :--- | :--- |
| **P2.1** | **提升测试覆盖率**: 作为项目维护者，我需要高覆盖率的单元测试来保证代码质量和重构的安全性。 | 核心模块（解析、后处理等）的单元测试覆盖率 > 80%。 |
| **P2.2** | **完善开发者文档**: 作为新加入的开发者，我需要清晰的文档来快速理解项目架构和各模块的职责。 | 提供完整的 API 文档、代码注释和一份详细的 `README.md`。 |

---

## 5. 附录

- **v1.0 评审报告**: `Mineru2Questions_Review_Report.md`
- **官方对齐仓库**: [OpenDCAI/DataFlow](https://github.com/OpenDCAI/DataFlow)
- **本项目仓库**: [shcming2023/Mineru2Questions](https://github.com/shcming2023/Mineru2Questions)
