# 产品需求文档 (PRD): Mineru2Questions

**版本**: 3.0
**状态**: 定稿
**修订日期**: 2026-02-20
**作者**: Manus AI

> **自包含声明**: 本文档是 Mineru2Questions 项目的唯一标准文档（取代 v2.0）。它涵盖了项目的全部背景、目标、功能需求、技术规格和数据定义，不依赖于任何外部文档、历史对话或代码注释。任何与本文档冲突的外部信息，以本文档为准。

---

## 修订历史

| 版本 | 日期 | 修订人 | 主要变更 |
| :--- | :--- | :--- | :--- |
| 1.0 | 2026-01-15 | 初始团队 | 初版，复刻 DataFlow 官方流水线，尝试同时抽取题目和远距离答案 |
| 1.1 | 2026-01-28 | 初始团队 | 简化为仅抽取题目，放弃远距离答案匹配 |
| 2.0 | 2026-02-15 | Manus AI | **重大重构**。引入"双 LLM 流水线"，增加章节预处理与验证容错算子；将 ChapterOverwrite 修订为 ChapterMerge（融合而非强制覆盖）；新增 MinerU 解析前置步骤；补充完整前端 UI/UX 需求；按照"十步法"标准重写为全面、完整、自包含的唯一标准文档 |
| 3.0 | 2026-02-20 | Manus AI | **与当前代码对齐**。将"双 LLM 流水线"架构描述精确化为"自适应三轨混合架构"；更新路线图（标注 P0/P1 已完成项，明确下一迭代重点）；补全附录 F（已知问题与限制）；补全附录 A–G（之前仅有目录而无正文）；修正 Home 页面标题为通用名称；实现章节预处理失败时的优雅降级；归档测试脚本；统一全项目版本号 |

---

## 目录

1. [产品概述与战略演进](#1-产品概述与战略演进)
2. [目标用户与使用场景](#2-目标用户与使用场景)
3. [产品原则](#3-产品原则)
4. [功能需求：前端与用户交互 (UI/UX)](#4-功能需求前端与用户交互-uiux)
5. [功能需求：后端核心流水线](#5-功能需求后端核心流水线)
6. [系统架构与技术栈](#6-系统架构与技术栈)
7. [发布标准](#7-发布标准)
8. [开发路线图](#8-开发路线图)
9. [附录 A：数据模型 (TypeScript 类型定义)](#9-附录-a数据模型-typescript-类型定义)
10. [附录 B：数据库 Schema (Drizzle ORM)](#10-附录-b数据库-schema-drizzle-orm)
11. [附录 C：API 接口 (tRPC 路由)](#11-附录-capi-接口-trpc-路由)
12. [附录 D：LLM 预设提供商](#12-附录-dllm-预设提供商)
13. [附录 E：文件系统约定](#13-附录-e文件系统约定)
14. [附录 F：已知问题与限制](#14-附录-f已知问题与限制)
15. [附录 G：历史关键发现与教训总结](#15-附录-g历史关键发现与教训总结)

---

## 1. 产品概述与战略演进

### 1.1 价值主张 (Elevator Pitch)

**对于**需要将海量、非结构化的 PDF 教育文档（如教材、讲义、试卷、练习册，涵盖数学、语文、理化等多学科）转化为高质量、结构化数据的**数据工程师和 AI 产品团队**，**Mineru2Questions 是一个**高保真结构化内容解析引擎，**它能够**通过一个鲁棒的、可观测的"自适应三轨混合 LLM 流水线"，精确地提取题目内容并还原其在原始文档中的章节归属关系。**不同于**那些仅做简单 OCR 或依赖脆弱规则的传统工具，**我们的产品**提供了工业级的可靠性和可追溯性，确保每一条提取数据的准确性和结构完整性，为下游智能题库、学习分析和 AI 助教等应用提供最坚实的数据基石。

### 1.2 项目演进历史

本项目基于 OpenDCAI/DataFlow 官方仓库（`PDF_VQA_extract_optimized_pipeline`）进行二次开发，经历了五个关键阶段。

**第一阶段：复刻官方仓库 (v1.0 - v1.1)**

团队完整复刻了 DataFlow 官方流水线的核心算子，并增加了 Web 交互界面和任务管理功能。v1.1 做出关键产品决策：**放弃远距离答案匹配，聚焦于高质量题目抽取**，仅保留与题目紧邻的例题解答（50 Block 以内）。

**第二阶段：修复阻塞性缺陷 (v1.2 - v1.6)**

集中解决多个导致系统无法正常工作的严重缺陷：BlockFlattener 展平逻辑引入、API 端点回归修复、超时单位错误修复（300ms vs 300s）、并发池恢复。v1.6 里程碑：首次成功产出 851 道题目。

**第三阶段：数据质量优化 (v1.8 - v2.0)**

聚焦于提升抽取结果的数据质量。v1.9 将去重策略改为基于 `questionIds`（Block ID 序列）。v2.0 实现了 Sanity Check + 自动重试机制，稳定产出 846 题。

**第四阶段：章节预处理引入 (v2.0 PRD 阶段)**

引入"双 LLM 流水线"架构：在题目抽取之前，增加独立的 `ChapterPreprocess` 算子，使用长上下文 LLM 通读全文构建章节映射表。同时实现 ChapterMerge（融合而非强制覆盖）策略。

**第五阶段：架构精化与鲁棒性强化 (当前 - v3.0)**

将"双 LLM 流水线"架构升级为"**自适应三轨混合架构**"（见 §5.3），新增 ChapterValidation 容错验证算子，修正 ChapterMerge 标题校验策略，实现章节预处理失败时的**优雅降级**（降级而非任务失败），完成超长公式截断，统一前端 UI 为多学科通用产品定位。

### 1.3 产品目标

| 目标类型 | 目标描述 | 核心衡量指标 (KPI) | 目标值 |
| :--- | :--- | :--- | :--- |
| **核心目标** | 题目提取完整性 | 提取完整率（基于 MinerU 解析结果，而非原书） | > 99% |
| **核心目标** | 章节归属准确性 | 章节覆盖率（有章节标题的题目占比） | > 99% |
| | | 章节准确率（章节路径与人工标注一致的题目占比） | > 95% |
| **工程目标** | 流水线鲁棒性 | LLM 输出有效率（成功解析并验证通过的 LLM 输出占比） | > 98% |
| **商业目标** | 降低人工成本 | 人工干预率（需要人工修正的题目占比） | < 1% |

> **关于"提取完整率"的说明**: 该指标衡量的是"MinerU 已正确解析出的题目中，本系统成功提取的比例"。MinerU 本身的 OCR 错误或遗漏不计入本系统的失败。

---

## 2. 目标用户与使用场景

### 2.1 核心用户原型

**姓名**: 张伟 (David Zhang)

**角色**: AI 公司数据工程师

**背景**: 32 岁，计算机科学硕士，在一家专注于 K12 教育的 AI 创业公司工作 3 年。负责构建和维护公司的数据处理流水线，为下游的"AI 错题本"、"个性化推荐"等产品提供数据支持。精通 Python 和 SQL，熟悉 Docker、Kubernetes 和主流云服务。对 LLM 有基本了解，能够通过 API 调用模型，但不是算法专家。

**痛点**:

> "每周，市场部都会给我们上百份 PDF 格式的各科新教辅材料。我的任务就是把里面的题目都扒出来，放到我们的题库里。最头疼的是，业务方要求题目必须带着它所属的章节，比如'第一章 > 第二节 > 函数的单调性'，这样才能做知识点分析。现在的工具要么提不出来，要么提出来的都是错的，我每周至少要花一天时间手动去修正这些章节信息，简直是噩梦。"

**目标**:
1. **自动化**: 找到一个能自动、准确地从 PDF 中提取题目和章节信息的工具
2. **高准确性**: 特别是章节归属关系，人工干预率 < 1%
3. **可观测与可追溯**: 当提取出错时，能快速定位问题所在
4. **易于集成**: 工具最好能提供稳定的 API

### 2.2 用户故事

| ID | 作为... | 我希望... | 以便... | 优先级 |
| :--- | :--- | :--- | :--- | :--- |
| US-000 | 数据工程师 | 将教育 PDF 通过 MinerU 解析成 `content_list.json` + `images/` 等标准输出物 | 供本系统的提取任务使用 | **前置条件** |
| US-001 | 数据工程师 | 上传一个包含 `content_list.json` 和 `images/` 的 MinerU 输出文件夹，就能启动一个完整的提取任务 | 快速开始工作，而不需要复杂的预处理 | **必须有** |
| US-002 | 数据工程师 | 在一个统一的界面管理所有 LLM 的 API Key 和模型配置 | 方便地测试和切换不同的模型 | **必须有** |
| US-003 | 数据工程师 | 实时查看任务的处理进度、分块状态和详细日志 | 及时了解任务健康状况 | **必须有** |
| US-004 | 数据工程师 | 在任务完成后，能方便地预览和下载结构化的结果 (JSON/Markdown) | 快速验证提取质量，并将数据交付给下游团队 | **必须有** |
| US-005 | 数据工程师 | 当任务失败或结果不理想时，能一键重跑任务，并对比新旧两个版本的结果差异 | 高效地调试 Prompt 或配置 | **应该有** |
| US-006 | 数据工程师 | 系统能自动检测并修复 LLM 输出的常见错误 | 提高流水线的成功率 | **必须有** |

---

## 3. 产品原则

**原则一：准确性高于一切 (Accuracy Over All)**

在速度、成本和准确性之间权衡时，永远优先选择准确性。一条错误的或结构不完整的数据会给下游系统带来数倍的修复成本。

**原则二：过程必须可观测 (Observability is a Feature)**

系统不能是一个"黑盒"。用户必须能够清晰地看到数据处理的每一个环节、每一个中间产物和每一条决策日志。

**原则三：坚持 ID-Only (ID-Only is the Law)**

LLM 的职责是"理解结构"而非"创造内容"。流水线中，LLM 只允许输出对 `content_list.json` 中 Block ID 的引用（ID / ID 区间 / ID 列表）。所有最终文本都必须通过 ID 回填得到。明确反对：让 LLM 输出自由文本题干/答案再做匹配。

**原则四：拥抱失败，优雅降级 (Embrace Failure, Degrade Gracefully)**

系统设计必须将"失败"作为一等公民来考虑，在每个环节都建立验证、重试、告警和回退机制，确保局部失败不会导致整个任务的灾难性崩溃。**特别地，当章节预处理失败时，系统必须能够回退到使用题目抽取阶段自带的章节信息，而非让整个任务失败。** 这是 v3.0 已实现的关键设计决策。

**原则五：不靠硬编码，追求可泛化 (Generalize, Don't Hardcode)**

系统必须能够兼容多种教育文本（不同学科、不同排版、不同题型、不同来源）。明确反对通过"硬编码 if/else + 特例补丁"来追求短期效果。

---

## 4. 功能需求：前端与用户交互 (UI/UX)

本系统采用单页应用 (SPA) 架构，通过左侧导航栏 + 右侧内容区的 Dashboard 布局组织所有页面。

### 4.1 整体布局 (`DashboardLayout`)

**目的**: 提供一致的导航和页面布局框架。

**组件与交互**:
- 左侧为固定的垂直导航栏，包含以下入口：
  - **首页** (`/`): 系统概览仪表盘
  - **任务列表** (`/tasks`): 所有任务的管理中心
  - **新建任务** (`/tasks/new`): 创建新的提取任务
  - **历史记录** (`/history`): 已完成任务的历史记录（与任务列表定位差异详见 §4.8）
  - **设置** (`/settings`): LLM 配置管理
- 导航栏底部显示当前登录用户信息和登出按钮
- 右侧为内容展示区，根据路由动态渲染对应页面

### 4.2 首页 (`Home`)

**目的**: 提供系统概览和快速入口。产品名称统一使用 **Mineru2Questions**，覆盖多学科（数学、语文、理化等），不应写死为特定学科。

**组件与交互**:
- **统计卡片区域**: 展示"进行中的任务数"、"已完成的任务数"、"总提取题目数"
- **最近任务列表**: 展示最近创建或更新的 5 个任务，显示任务名称、状态徽标（蓝色=处理中、绿色=已完成、红色=失败、灰色=排队中）和创建时间
- **快速操作按钮**: "新建任务"按钮，点击跳转到 `NewTask` 页面
- **空状态**: 当没有任何任务时，显示引导文案和"创建第一个任务"的按钮

### 4.3 新建任务 (`NewTask`)

**目的**: 引导用户完成新提取任务的创建。

**组件与交互**:
- **任务名称输入框**: 必填字段，用于标识任务（如"人教版高一数学必修一"）
- **文件上传区**: 支持拖拽或点击上传 MinerU 输出文件夹（必须包含 `content_list.json` 和 `images/`），上传后显示 Block 数量和图片数量
- **LLM 配置选择**:
  - **"章节预处理模型"**: 仅显示 `purpose` 为 `long_context` 或 `general` 的已配置 LLM
  - **"题目抽取模型"**: 仅显示 `purpose` 为 `vision_extract` 或 `general` 的已配置 LLM
  - 如果用户尚未配置任何 LLM，显示黄色提示并提供跳转到"设置"页面的链接

### 4.4 任务列表 (`Tasks`)

**目的**: 展示所有任务（进行中 + 已完成 + 失败），提供操作入口。

**组件与交互**:
- 以表格形式展示全部任务，支持按状态过滤
- 每行显示：任务名称、状态徽标、创建时间、提取题目数、操作按钮（查看、重试、删除）
- **"新建任务"按钮**放置在页面顶部

### 4.5 任务详情 (`TaskDetail`)

**目的**: 提供任务处理的实时监控、结果展示和调试支持。

**组件与交互**:

**A. 任务概览区**:
- 显示任务名称、状态徽标、创建时间、开始时间、完成时间
- 显示关联的 LLM 配置名称（章节预处理模型 + 题目抽取模型）
- 显示提取的题目总数（大字号突出显示）
- 如果任务属于某个"族系"（有父任务或子任务），显示族系标识和版本号

**B. 操作按钮区**:
- **"下载结果"**: 仅在 `completed` 状态可用，下载 `questions.json` 和 `questions.md`
- **"下载调试包"**: 仅在 `completed` 或 `failed` 状态可用，打包下载任务目录下的所有文件
- **"重试"**: 在 `completed` 或 `failed` 状态可用，创建新的子任务
- **"暂停"/"继续"**: 仅在 `processing` 状态显示（当前后端为空实现，详见 §4.9）

**C. 实时日志区**:
- 以类终端样式（深色背景、等宽字体）的滚动窗口展示后端处理日志
- 每条日志显示时间戳、级别标签（`INFO`/`WARN`/`ERROR`/`DEBUG`）、阶段标签（`loading`/`chunking`/`chapter_preprocess`/`extracting`/`merging`/`saving`）、消息内容
- 在 `processing` 状态下自动轮询（每 3 秒）获取最新日志

**D. 分块进度区**:
- 以网格形式可视化展示所有数据块（Chunk）的处理状态
- 每个块显示为小方块：灰色（待处理）、蓝色脉冲（处理中）、绿色（成功）、红色（失败）

**E. 结果预览区** (仅在 `completed` 状态显示):
- 提供两个 Tab：**Markdown** 和 **JSON**，均支持语法高亮和大文件分页渲染

**F. 历史版本区** (仅在任务有父/子任务时显示):
- 显示当前任务所属"族系"中的所有版本列表，提供"对比"按钮

### 4.6 任务对比 (`TaskCompare`)

**目的**: 直观对比两个任务版本的结果差异，帮助用户评估 Prompt 或配置调整的效果。

**组件与交互**:
- **版本选择区**: 两个下拉框，分别用于选择"基准版本"和"对比版本"
- **统计对比**: 顶部显示两个版本的关键指标对比，差异以颜色标识
- **差异视图**: 以分屏、差异高亮（类似 Git Diff）的方式展示两个版本 Markdown 输出的逐行差异

### 4.7 设置 (`Settings`)

**目的**: 统一管理所有外部 LLM 服务的 API 配置。

**组件与交互**:

**A. 配置列表**: 以表格形式展示所有已添加的 LLM 配置，每行显示配置名称、提供商、模型名称、用途标签（`视觉抽取`/`长文本推理`/`通用`）、并发数、是否为默认

**B. 新建/编辑模态框**:
- **预设提供商选择**: SiliconFlow、阿里云百炼、OpenAI、Anthropic Claude、Google Gemini、DeepSeek、自定义 API
- **配置字段**: 配置名称（必填）、API URL（必填）、API Key（必填）、模型名称（必填）、用途（必填）、并发数（默认 5）、超时时间（默认 300 秒）、上下文窗口（默认 128000 tokens）、设为默认
- **"测试连接"按钮**: 向 LLM API 发送测试消息，验证连通性

### 4.8 历史记录 (`History`)

**目的**: 与 `Tasks` 页面的功能定位区分如下：
- **Tasks (`/tasks`)**: 任务管理中心，包含全部状态的任务，侧重操作（新建、重试、删除）
- **History (`/history`)**: 历史归档视图，仅显示已完成（`completed`）的任务，侧重快速查看和下载结果

> **v3.0 说明**: 两个页面保持并存，但在导航和 UI 中需明确差异化定位，避免用户困惑。

### 4.9 暂停/取消功能（Should-have，下一迭代）

当前 v3.0 中：
- **前端**: "暂停"/"继续"按钮已在 TaskDetail 页面存在
- **后端**: `pauseTaskProcessing` 和 `cancelTaskProcessing` 为空实现（仅打印警告日志），**不实际暂停任务**
- **优先级**: Should-have，纳入下一迭代计划（见 §8.2 P1-新增）
- **实现思路**: 需引入任务状态机 + 信号量机制，在并发池的每个 Worker 迭代中检查信号

---

## 5. 功能需求：后端核心流水线

### 5.1 流水线总览

本系统的核心是一条由 7 个算子组成的**自适应三轨混合 LLM 流水线**。之所以称为"三轨"，是因为章节预处理阶段采用了三种互补策略的自适应组合（见 §5.3）。

```
[输入: content_list.json + images/]
        │
        ▼
┌─────────────────────────┐
│ ① BlockFlattener        │ → FlatBlock[]
└─────────┬───────────────┘
          │
          ▼
┌─────────────────────────────────────────────────┐
│ ② ChapterPreprocess (自适应三轨混合架构)          │
│                                                  │
│  轨道一: TOC-Driven  (纯代码，检测目录页)         │
│  轨道二: Pattern-Driven (正则锚点，无 LLM)        │
│  轨道三: LLM-Assisted (逐页/小窗口 LLM)          │
│                                                  │
│  自适应调度器 → 选择最优轨道组合 → 融合结果       │
└─────────┬───────────────────────────────────────┘
          │
          ▼
┌─────────────────────────┐
│ ③ ChapterValidation     │ → chapter_flat_map.json | null
│    (验证与容错)          │
└─────────┬───────────────┘
          │ (null → 优雅降级，使用题目抽取侧章节)
          ▼
┌─────────────────────────┐
│ ④ QuestionExtract       │ → XML 输出 (含 chapter_title)
│    (视觉/通用 LLM)      │
└─────────┬───────────────┘
          │
          ▼
┌─────────────────────────┐
│ ⑤ Parser                │ → ExtractedQuestion[]
│    (ID 回填)             │
└─────────┬───────────────┘
          │
          ▼
┌─────────────────────────┐
│ ⑥ ChapterMerge          │ → 融合后的 ExtractedQuestion[]
│    (章节信息融合)        │
└─────────┬───────────────┘
          │
          ▼
┌─────────────────────────┐
│ ⑦ PostProcess & Export   │ → questions.json + questions.md
│    (去重、排序、导出)    │
└─────────┘
```

> **优雅降级保障 (v3.0)**: 当算子 ② 章节预处理抛出任何异常时，系统不再终止整个任务，而是将 `chapterResult` 设为 `null`，继续执行算子 ④，最终在算子 ⑥ 中回退到使用题目抽取阶段的 LLM 章节判断。这一行为符合原则四（优雅降级）。

### 5.2 算子 ①：BlockFlattener

**职责**: 将 MinerU 输出的嵌套 `content_list.json` 展平为一维的 `FlatBlock[]` 数组，为后续所有算子提供统一的、连续编号的输入。

**核心规则**:
- 嵌套的 `list` 类型必须递归展平为独立的 Block，每个子项获得独立的 `id`
- `equation` 类型的 `latex` 字段必须被保留并正确转换为文本表示
- 噪声 Block（页码、页眉页脚等）应被过滤，但过滤规则必须是保守的（宁可保留噪声，不可误删有效内容）
- `id` 的连续性是整个流水线的基石——后续所有算子的 ID 引用都基于此

**输出**: `FlatBlock[]`，同时写入 `debug/formatted_blocks.json`

**验收标准**: 输出的 `FlatBlock[]` 的 `id` 必须从 0 开始连续递增，无间断。

### 5.3 算子 ②：ChapterPreprocess（自适应三轨混合架构）

**职责**: 识别文档中所有章节标题及其 Block ID，构建全局章节结构。

**三轨架构**:

| 轨道 | 方式 | 适用场景 | 优先级 |
| :--- | :--- | :--- | :--- |
| **轨道一：TOC-Driven** | 纯代码检测目录页，提取"标题...页码"模式条目，在正文中定位对应锚点 | 有规范目录页的文档（教材为主） | 最高 |
| **轨道二：Pattern-Driven** | 正则模式匹配正文中的章节标题（"第X章"、"第X节"等），无 LLM 调用 | 标题格式规范但无目录的文档 | 中 |
| **轨道三：LLM-Assisted** | 逐页/小窗口调用 LLM 辅助识别章节边界 | 标题格式不规范、复杂排版文档 | 兜底 |

**自适应调度器**: 根据文档特征（是否有目录页、标题正则命中率、Block 总数）选择最优轨道组合，并融合多轨道结果。设计原则：**代码优先，LLM 兜底**。

**关键约束**:
- 当 Block 总数超过 LLM 上下文窗口时，自动切换分块模式，确保每个 Chunk 的 LLM 输出使用全局 Block ID（而非 Chunk 内部相对序号）
- 必须将 LLM 的原始输出保存到 `debug/` 目录

**验收标准**: 输出的每个 `block_id` 必须在 `FlatBlock[]` 的 ID 范围内。章节标题顺序与文档出现顺序一致。

### 5.4 算子 ③：ChapterValidation

**职责**: 验证 `ChapterPreprocess` 的输出质量，或在验证失败时输出 `null` 以触发回退。

**核心规则**:
- 验证 JSON 格式合规、所有 `block_id` 在合法范围内、章节覆盖逻辑合理（无大面积空白、无严重重叠）
- 验证失败时必须输出 `null` 而非使用错误数据
- 验证结果必须记录到任务日志

**验收标准**: 当 LLM 输出存在格式错误、ID 越界或逻辑异常时，必须检测到并输出 `null`，而非让错误数据流入下游。

### 5.5 算子 ④：QuestionExtract

**职责**: 使用视觉/通用 LLM 对 `FlatBlock[]` 进行分块处理，从每个 Chunk 中抽取题目结构。

**核心规则**:
- **ID-Only 原则**: LLM 只允许输出 Block ID 引用，不允许输出自由文本题干或答案
- **分块策略**: 按固定 Block 数量（默认 100 个/Chunk，重叠 30 个）切分，保持 Block 连续性
- **并发控制**: 通过并发池并行处理，并发数由 `maxWorkers` 控制（默认 5）
- **Sanity Check + 重试**: 输出题目数异常少时触发重试（最多 N 次）
- 每个 Chunk 的 Prompt 和 LLM 原始输出必须保存到 `debug/` 和 `logs/` 目录

> **待优化项（下一迭代）**: 当前按 Block 数量切块；路线图计划改为按 Token 数量切块，以更精确适配不同模型的上下文窗口。

**验收标准**: 提取完整率 > 99%，LLM 输出有效率 > 98%。

### 5.6 算子 ⑤：Parser

**职责**: 解析 LLM 的 XML 输出，通过 ID 回填从 `FlatBlock[]` 中还原题目的完整文本。

**核心规则**:
- **双模式解析**: 先尝试严格模式（要求 XML 完全合规），失败后回退到宽松模式（正则提取关键字段）
- **ID 回填**: 将 LLM 输出的 Block ID 列表映射回 `FlatBlock[]`，拼接对应 Block 的文本内容
- **超长公式截断**: 对超长公式（`equation` 类型）的回填文本进行截断，避免输出文件过大（v3.0 已实现）
- 解析失败的题目应记录到日志中，但不应导致整个 Chunk 的解析失败

**验收标准**: 对格式正确的 LLM 输出，解析成功率必须为 100%。

### 5.7 算子 ⑥：ChapterMerge

**职责**: 融合两个来源的章节信息——`chapter_flat_map`（来自算子 ③）和每道题目自带的 `chapter_title`（来自算子 ⑤）。

**核心规则**:
- **当 `chapter_flat_map` 为 `null` 时（回退模式）**: 直接使用每道题目自带的 `chapter_title`，不做任何覆盖
- **当 `chapter_flat_map` 可用时**: 根据每道题目的 Block ID 在 `chapter_flat_map` 中查找章节，优先采用预处理路径式标题
- **标题校验**: 对标题进行正则校验，过滤误识别的目录条目或噪声（v3.0 已修正校验正则，移除对 `>` 的误判）
- 必须记录每道题目的章节来源（"来自章节预处理"或"来自题目抽取"或"融合"）

**验收标准**: 当章节预处理成功时，章节覆盖率 > 99%，章节准确率 > 95%。当章节预处理失败时，系统必须正常回退，不输出错误的章节信息。

### 5.8 算子 ⑦：PostProcess & Export

**职责**: 对所有题目进行去重、排序和格式化，生成最终的交付文件。

**核心规则**:
- **去重**: 基于 `questionIds`（Block ID 序列）进行精确去重。**明确不使用** `(title, label)` 或 `(title, label, page_idx)` 等不稳定的去重键
- **排序**: 按页码 (`page_idx`) 和 Block ID 升序排列
- **Markdown 格式**: 按章节分组，每个章节下列出所有题目（含题号、题干、关联图片、答案/解题过程）
- **JSON 格式**: 每道题目包含完整的结构化字段（详见附录 A）

---

## 6. 系统架构与技术栈

### 6.1 架构概览

```
┌─────────────────────────────────────────────────────┐
│                     前端 (React SPA)                 │
│  Vite + React + TypeScript + TailwindCSS + shadcn   │
│  Wouter (路由) + @tanstack/react-query (数据获取)    │
└──────────────────────┬──────────────────────────────┘
                       │ tRPC (HTTP)
                       ▼
┌─────────────────────────────────────────────────────┐
│                     后端 (Node.js)                   │
│  Hono (HTTP) + tRPC (API) + Drizzle ORM (数据库)     │
│                                                      │
│  ┌─────────────────────────────────────────────┐    │
│  │       核心流水线 (7 个算子)                   │    │
│  │  BlockFlattener → ChapterPreprocess →        │    │
│  │  ChapterValidation → QuestionExtract →       │    │
│  │  Parser → ChapterMerge → PostProcess         │    │
│  └─────────────────────────────────────────────┘    │
└──────────┬──────────────────────┬───────────────────┘
           │                      │
           ▼                      ▼
┌──────────────────┐   ┌──────────────────────────┐
│  SQLite 数据库    │   │  外部 LLM 服务            │
│  (Drizzle ORM)   │   │  (OpenAI 兼容 API)       │
│  本地文件存储     │   │  SiliconFlow / 百炼 /    │
└──────────────────┘   │  OpenAI / Anthropic /    │
                       │  Google / DeepSeek / 自定义│
                       └──────────────────────────┘
```

### 6.2 技术栈约束

| 层级 | 技术选型 | 版本要求 |
| :--- | :--- | :--- |
| **运行时** | Node.js | >= 22.x |
| **语言** | TypeScript | >= 5.x（严格模式） |
| **前端框架** | React | >= 18.x |
| **前端构建** | Vite | >= 5.x |
| **前端路由** | Wouter | >= 3.x |
| **前端数据获取** | @tanstack/react-query | >= 5.x |
| **UI 组件库** | shadcn/ui + Radix UI | 最新 |
| **CSS 框架** | TailwindCSS | >= 3.x |
| **后端 HTTP 框架** | Hono | >= 4.x |
| **API 层** | tRPC | >= 11.x |
| **数据库** | SQLite | - |
| **ORM** | Drizzle ORM | >= 0.38.x |
| **LLM 客户端** | OpenAI SDK | >= 4.x |
| **包管理器** | npm | >= 10.x |

**硬性约束**:
- **不引入 Python 依赖**: 整个项目必须在纯 Node.js/TypeScript 环境下运行
- **不重新执行 OCR**: 系统信任并基于 MinerU 的输出
- **LLM 通信协议**: 所有 LLM 调用必须通过 OpenAI 兼容的 `/chat/completions` API 端点

---

## 7. 发布标准

### 7.1 性能

| 指标 | 标准 | 测试条件 |
| :--- | :--- | :--- |
| 端到端处理时间 | **不超过 30 分钟** | 1500 页 PDF，包含约 5000 道题目，标准配置（并发数 5，超时 300 秒） |
| 前端页面首次加载 | < 3 秒 | 标准网络环境 |
| 任务列表查询响应 | < 500 毫秒 | 数据库中有 100 个任务 |
| 日志实时推送延迟 | < 5 秒 | 从后端产生日志到前端显示 |

### 7.2 可靠性

| 指标 | 标准 | 说明 |
| :--- | :--- | :--- |
| 题目提取完整率 | > 99% | 基于 MinerU 已正确解析的题目 |
| 章节覆盖率 | > 99% | 有章节标题的题目占比（章节预处理成功时） |
| 章节准确率 | > 95% | 章节路径与人工标注一致的题目占比 |
| LLM 输出有效率 | > 98% | 成功解析并验证通过的 LLM 输出占比 |
| 人工干预率 | < 1% | 需要人工修正的题目占比 |
| 系统内部错误失败率 | < 1% | 非 LLM/网络原因导致的任务失败（章节预处理失败不再计入此指标，因已实现优雅降级） |

### 7.3 可用性

| 指标 | 标准 |
| :--- | :--- |
| 新用户完成首次任务 | < 10 分钟（不含 MinerU 解析时间） |
| 任务失败时的诊断时间 | < 5 分钟（用户能通过日志和调试文件定位问题根因） |

### 7.4 验收测试标准

> **v3.0 新增**: 明确定义 KPI 目标值的验收测试方案。

| KPI | 测试数据集 | 测量方法 | 验收人 |
| :--- | :--- | :--- | :--- |
| 题目提取完整率 > 99% | 人工标注数据集（不少于 3 份不同学科/出版社的 PDF，共不少于 500 道题目，MinerU 已成功解析） | 以人工标注题目数为基准，统计系统提取数 / 基准数 | 产品负责人 + 数据工程师各 1 名 |
| 章节准确率 > 95% | 同上 | 随机抽取 100 道题目，人工核对章节路径是否与文档中实际章节一致 | 同上 |
| LLM 输出有效率 > 98% | 任意 10 次生产任务的日志 | 统计 `chapter_preprocess` + `extracting` 阶段的 LLM 调用成功次数 / 总调用次数 | 数据工程师 |

---

## 8. 开发路线图

路线图基于 v3.0（2026-02-20）的当前状态更新，标注各项完成情况。

### 8.1 已完成（v3.0 及之前）

| 编号 | 任务 | 完成版本 | 说明 |
| :--- | :--- | :--- | :--- |
| ✅ P0-1 | **ChapterValidation 算子** | v3.0 | 已在 `chapterPreprocessV2.ts` 中实现目录树验证步骤，验证失败时返回空目录触发下游优雅降级 |
| ✅ P0-2 | **ChapterOverwrite → ChapterMerge** | v2.x | 已在 `extraction.ts` / `taskProcessor.ts` 中实现融合策略，支持回退 |
| ✅ P0-3 | **分块模式下 ID 空间问题** | v2.x | 已在 Prompt 和后处理中确保 LLM 输出使用全局 Block ID |
| ✅ P0-4 | **章节预处理失败优雅降级** | **v3.0** | `taskProcessor.ts` 中已将 `throw err` 改为 `chapterResult = null`，任务不再因章节预处理失败而整体失败 |
| ✅ P1-1 | **目录页误识别防护** | v2.x | ChapterPreprocessV2 轨道一（TOC-Driven）已专门处理目录页检测与过滤 |
| ✅ P1-2 | **ChapterMerge 标题校验修正** | v3.0 | 修正标题校验正则，移除对 `>` 的误判 |
| ✅ P2-x | **超长公式截断** | v2.x | Parser 中已实现超长公式回填截断 |
| ✅ P2-x | **Home 页面标题通用化** | **v3.0** | 从"数学题目提取器"改为"Mineru2Questions"，覆盖多学科 |

### 8.2 下一迭代重点（P1 优先级）

| 编号 | 任务 | 说明 | 关联用户故事 |
| :--- | :--- | :--- | :--- |
| P1-新增-1 | **实现暂停/取消功能** | 在并发池每次迭代中检查取消信号，实现真正的任务暂停和取消（当前后端为空实现）。前端按钮已就绪，仅需后端实现。 | US-003 |
| P1-新增-2 | **按 Token 数量切块** | 当前按 Block 数量（100 个/Chunk）切块，存在 Token 超限风险。改为按估算 Token 数切块，更精确适配不同模型的上下文窗口。 | US-001, US-006 |
| P1-3 | **任务对比功能完善** | TaskCompare 页面差异算法需优化，确保能准确展示两个版本之间的增删改差异。 | US-005 |
| P1-新增-3 | **History/Tasks 页面明确差异化** | 在 UI 上明确两个页面的定位（Tasks=全部任务管理，History=已完成归档），防止用户困惑。 | US-003 |

### 8.3 后续迭代（P2 优先级）

| 编号 | 任务 | 说明 |
| :--- | :--- | :--- |
| P2-1 | **增加单元测试** | 为核心流水线的每个算子编写单元测试，覆盖正常路径和异常路径，目标覆盖率 > 70% |
| P2-2 | **端到端验收测试** | 基于 §7.4 定义的测试数据集，建立自动化验收测试流程 |
| P2-3 | **探索远距离答案匹配** | 研究如何将书末答案与正文题目进行可靠配对（当前明确不支持） |
| P2-4 | **支持批量任务** | 允许用户一次上传多个 MinerU 输出文件夹，批量创建和执行任务 |

---

## 9. 附录 A：数据模型 (TypeScript 类型定义)

```typescript
/** 展平后的 Block（BlockFlattener 输出） */
export interface FlatBlock {
  id: number;             // 全局唯一 ID（从 0 开始连续递增）
  type: string;           // 类型: text, image, table, equation, list 等
  text?: string;          // 文本内容
  img_path?: string;      // 图片相对路径
  image_caption?: string; // 图片标题（合并为单个字符串）
  page_idx?: number;      // 页码索引（从 0 开始）
  text_level?: number | null; // 文本层级（用于标题，null 表示非标题）
}

/** ChapterPreprocess 输出的章节候选条目 */
export interface ChapterCandidate {
  block_id: number;       // 该章节标题对应的 Block ID
  title: string;          // 章节标题文本
  level: number;          // 层级（1=章、2=节、3=小节）
}

/** ChapterValidation 输出的章节平铺条目 */
export interface ChapterFlatEntry {
  blockId: number;        // 章节标题 Block ID
  title: string;          // 章节标题
  level: number;          // 层级
  startBlockId: number;   // 本章节内容起始 Block ID
  endBlockId: number;     // 本章节内容结束 Block ID（含）
}

/** 从 LLM 输出中抽取的 QA 对（Parser 输出） */
export interface ExtractedQuestion {
  label: string;          // 题号（如 "1"、"例1"、"习题3"）
  question: string;       // 问题文本（通过 questionIds 回填）
  answer: string;         // 答案（可以是短文本）
  solution: string;       // 解答过程（通过 solutionIds 回填）
  chapter_title: string;  // 章节标题（ChapterMerge 后的最终值）
  images: string[];       // 关联图片路径列表
  // 追溯元数据
  questionIds?: string;   // 问题的 Block ID 序列（如 "10,11,12"）
  solutionIds?: string;   // 解答的 Block ID 序列
  chapterTitleIds?: string; // 章节标题的 Block ID 序列
  chunkIndex?: number;    // 来源数据块索引
  sourcePageIndex?: number; // 来源页码
  chapterSource?: 'preprocess' | 'extraction' | 'merged'; // 章节来源
}

/** LLM 配置 */
export interface LLMConfig {
  apiUrl: string;         // LLM API 地址
  apiKey: string;         // API 密钥
  modelName: string;      // 模型名称
  maxWorkers: number;     // 最大并发数（默认 5）
  timeout: number;        // 超时时间（毫秒，存储时为秒，使用前乘以 1000）
  maxRetries?: number;    // 最大重试次数（默认 3）
}

/** 章节预处理专用 LLM 配置 */
export interface ChapterLLMConfig {
  apiUrl: string;
  apiKey: string;
  modelName: string;
  timeout: number;        // 毫秒
  contextWindow?: number; // 上下文窗口大小（tokens，默认 128000）
}

/** ChapterPreprocess 整体结果 */
export interface ChapterPreprocessResult {
  flatMap: ChapterFlatEntry[]; // 章节平铺映射表
  totalEntries: number;        // 总章节条目数
  coverageRate: number;        // Block 覆盖率（0-1）
}
```

---

## 10. 附录 B：数据库 Schema (Drizzle ORM)

数据库文件位于项目根目录的 `sqlite.db`，Schema 定义位于 `drizzle/schema.ts`。

**主要表**:

| 表名 | 说明 |
| :--- | :--- |
| `users` | 用户信息（OAuth 登录） |
| `llm_configs` | LLM API 配置（含 `purpose` 字段：`vision_extract`/`long_context`/`general`） |
| `extraction_tasks` | 提取任务（含 `chapterConfigId`、`parentTaskId`、`rootTaskId` 族系字段） |
| `page_processing_logs` | 逐 Chunk 处理记录（用于断点恢复，当前未完全启用） |
| `task_logs` | 任务实时日志（`level`/`stage`/`chunkIndex` 等字段） |
| `audit_logs` | 审计日志（合规性审查） |

**任务状态枚举**: `pending` / `processing` / `completed` / `failed` / `paused`

> **注意**: `paused` 状态在数据库 Schema 中已存在，但后端 `pauseTaskProcessing` 函数尚未实现实际暂停逻辑（v3.0）。

---

## 11. 附录 C：API 接口 (tRPC 路由)

所有 API 通过 tRPC 提供，主要路由组：

**`llmConfig` 路由组**:

| 方法 | 说明 |
| :--- | :--- |
| `llmConfig.list` | 获取当前用户的所有 LLM 配置 |
| `llmConfig.create` | 创建新 LLM 配置 |
| `llmConfig.update` | 更新 LLM 配置 |
| `llmConfig.delete` | 删除 LLM 配置 |
| `llmConfig.testConnection` | 测试 LLM API 连通性 |

**`task` 路由组**:

| 方法 | 说明 |
| :--- | :--- |
| `task.list` | 获取当前用户的所有任务 |
| `task.get` | 获取指定任务详情 |
| `task.create` | 创建新任务 |
| `task.retry` | 重试任务（创建子任务） |
| `task.pause` | 暂停任务（当前后端为空实现） |
| `task.cancel` | 取消任务（当前后端为空实现） |
| `task.getLogs` | 获取任务日志 |
| `task.getFamily` | 获取任务族系（所有版本） |

**`upload` 路由组**:

| 方法 | 说明 |
| :--- | :--- |
| `upload.contentList` | 上传 `content_list.json` 文件 |
| `upload.images` | 上传图片文件夹 |

**`result` 路由组**:

| 方法 | 说明 |
| :--- | :--- |
| `result.getJson` | 获取结果 JSON |
| `result.getMarkdown` | 获取结果 Markdown |
| `result.download` | 下载结果文件 |

---

## 12. 附录 D：LLM 预设提供商

系统预设以下 LLM 提供商（定义于 `shared/const.ts`）：

| 提供商 | API URL | 推荐模型 | 适用阶段 |
| :--- | :--- | :--- | :--- |
| **硅基流动 (SiliconFlow)** | `https://api.siliconflow.cn/v1` | `Qwen2.5-VL-72B-Instruct` | 题目抽取（支持视觉） |
| **阿里云百炼** | `https://dashscope.aliyuncs.com/compatible-mode/v1` | `qwen-vl-max` | 题目抽取（支持视觉） |
| **OpenAI** | `https://api.openai.com/v1` | `gpt-4o` | 题目抽取（支持视觉） |
| **Anthropic Claude** | `https://api.anthropic.com/v1` | `claude-3-5-sonnet-20241022` | 通用 |
| **Google Gemini** | `https://generativelanguage.googleapis.com/v1beta/openai` | `gemini-2.0-flash` | 章节预处理（超大上下文） |
| **DeepSeek** | `https://api.deepseek.com/v1` | `deepseek-chat` | 章节预处理 |
| **自定义 API** | 用户输入 | 用户输入 | 任意 |

**用途分类建议**:
- `vision_extract`（视觉抽取）: 需要支持图片输入的模型，用于第二阶段题目抽取
- `long_context`（长文本推理）: 上下文窗口大（≥ 128K tokens）的模型，用于第一阶段章节预处理
- `general`（通用）: 可同时用于两个阶段

---

## 13. 附录 E：文件系统约定

每个任务的文件统一存储在 `server/uploads/tasks/<taskId>/` 目录下：

```
server/uploads/tasks/<taskId>/
├── content_list.json          # MinerU 原始解析结果（用户上传）
├── images/                    # 图片文件夹（用户上传）
├── debug/
│   ├── formatted_blocks.json  # BlockFlattener 输出（FlatBlock[]）
│   ├── chapter_candidates.json # ChapterPreprocess 原始 LLM 输出
│   ├── chapter_flat_map.json  # ChapterValidation 输出（或 null）
│   ├── chunk_<N>_prompt.txt   # QuestionExtract 第 N 个 Chunk 的 Prompt
│   └── chunk_<N>_response.txt # QuestionExtract 第 N 个 Chunk 的 LLM 响应
├── logs/
│   └── extraction.log         # 流水线文本日志
└── results/
    ├── questions.json          # 最终结果（JSON 格式）
    └── questions.md            # 最终结果（Markdown 格式）
```

**命名约定**:
- 所有路径均使用相对路径存储到数据库，实际文件路径通过 `resolveFilePath()` 解析
- `contentListPath` 字段存储相对于 `server/` 的路径

---

## 14. 附录 F：已知问题与限制

> **v3.0 新增**: 本附录在 v2.0 中被引用但未完整填写。以下是截至 v3.0（2026-02-20）的完整已知问题列表。

### F.1 功能性已知问题

| 编号 | 问题描述 | 严重程度 | 状态 | 规避方案 |
| :--- | :--- | :--- | :--- | :--- |
| F-001 | **暂停/取消任务为空实现**: `pauseTaskProcessing` 和 `cancelTaskProcessing` 仅打印警告，不实际暂停任务 | 中 | 待实现（下一迭代） | 用户只能等待任务完成或在服务器端手动终止进程 |
| F-002 | **按 Block 数量切块存在 Token 超限风险**: 当单个 Block 内容很长时（如复杂表格），100 个 Block 可能超过模型的 Token 限制 | 中 | 待优化（下一迭代） | 适当减小 `MAX_CHUNK_SIZE`，或手动将超大文档拆分后上传 |
| F-003 | **章节预处理分块模式（轨道三）的 ID 偏移风险**: 在轨道三 LLM 分块处理时，如果 Prompt 未明确标注全局 ID，LLM 可能输出相对序号 | 低 | 已有防护（v2.x），待加强 | 查看 `debug/chapter_candidates.json`，手动核查 block_id 是否在合法范围内 |
| F-004 | **History 与 Tasks 页面功能重叠**: 两个页面均展示任务列表，差异化定位尚不清晰 | 低 | 待 UI 优化（下一迭代） | 了解区别：Tasks 含全部状态，History 仅含 completed |

### F.2 精度性已知限制

| 编号 | 限制描述 | 影响 | 说明 |
| :--- | :--- | :--- | :--- |
| F-L001 | **MinerU OCR 上限**: 系统准确率不能超过 MinerU 本身的 OCR 质量 | 不可避免 | 属于外部依赖，非本系统可控范围 |
| F-L002 | **复杂版面章节识别偏差**: 对于排版极不规范的文档（如手写扫描件、多栏布局），章节预处理准确率可能低于 95% | 中 | 在章节预处理失败时自动降级到题目抽取侧章节 |
| F-L003 | **目录页噪声**: 部分文档的目录页格式特殊，TOC-Driven 轨道可能将目录条目误识别为正文章节 | 低 | ChapterValidation 会检测异常结果并输出 null 触发降级 |
| F-L004 | **远距离答案不支持**: 章节末尾或书末的答案无法与题目自动关联 | 中 | 明确的产品范围外功能，计划在 P2 阶段研究 |

### F.3 性能已知限制

| 编号 | 限制描述 | 影响 | 说明 |
| :--- | :--- | :--- | :--- |
| F-P001 | **章节预处理增加总处理时间**: 章节预处理（特别是轨道三 LLM-Assisted 模式）会在题目抽取之前增加额外的 LLM 调用时间 | 中 | 可通过仅配置题目抽取模型（不配置章节预处理模型）来跳过章节预处理阶段 |
| F-P002 | **SQLite 并发写入限制**: 当多个任务同时处理时，SQLite 的写入锁可能成为瓶颈 | 低 | 当前单用户场景下影响不大，多用户场景下需考虑迁移到 PostgreSQL |

---

## 15. 附录 G：历史关键发现与教训总结

本附录总结了项目各阶段的关键教训，这些发现直接影响了当前的架构设计决策。

### G.1 数据输入端的质量决定一切

**背景**: v1.2 发现 MinerU 输出的 `list`、`equation` 等复杂类型未被正确展平，噪声块未被过滤，导致 ID 不连续、LLM 输入质量低。

**教训**: **优先修复数据输入端，而不是调整提示词**。提示词调优只能在输入质量达标的前提下才有效。引入 `BlockFlattener` 作为所有算子的统一预处理步骤是整个项目最重要的架构决策之一。

### G.2 微小的配置错误可以导致灾难性的输出崩溃

**背景**: v1.4 将超时参数的单位从秒错误地改为毫秒（300ms vs 300s），v1.3 将 API 端点路径从 `/chat/completions` 误删，均导致 0 题产出。

**教训**: 每次修改 LLM 配置相关代码后，必须进行端到端冒烟测试。超时、URL、认证等配置项的错误在开发期间极难通过代码审查发现，必须通过运行时验证。

### G.3 去重策略的稳定性影响结果可靠性

**背景**: v1.8 使用 `(title, label)` 二元组去重，因 `title` 不稳定导致过度去重，题目数从 851 降至 509（丢失 40%）。v1.9 改为基于 `questionIds`（Block ID 序列）去重，题目数恢复至 998，准确识别 54 组真正重复。

**教训**: 去重键必须是**内容稳定的**。Block ID 序列是唯一真正稳定的内容标识，因为它直接来自原始文档，不受 LLM 输出变化的影响。

### G.4 章节信息必须来自独立阶段，不能依赖分块 LLM

**背景**: 分块处理时，章节标题可能不在当前 Chunk 中，导致 LLM 无法正确识别章节归属（只能看到当前 Chunk 的内容，看不到全局章节结构）。

**教训**: 引入独立的章节预处理阶段（使用长上下文 LLM 通读全文），从全局视角构建章节映射，然后通过 ChapterMerge 将全局章节信息注入到每道题目中。这是"自适应三轨混合架构"引入的根本原因。

### G.5 强制覆盖策略在降级路径下会扩大损害

**背景**: 早期版本的"ChapterOverwrite"策略将章节预处理的结果无条件覆盖题目抽取阶段的章节信息。当章节预处理失败时，这会将正确的章节信息替换为错误的（甚至 null）。

**教训**: 永远不要用可能失败的结果覆盖可能正确的基线。"融合而非覆盖"（ChapterMerge）和"失败时不使用而非使用错误值"（ChapterValidation 输出 null）是正确的防御性设计。

### G.6 并发对性能至关重要，不要轻易退化为串行

**背景**: v1.5 将并发池错误退化为串行执行（`for...await` 替代了并发机制），处理时间从 2.4 分钟膨胀到 15 分钟（6.25 倍）。

**教训**: 并发处理是流水线性能的核心保障。任何重构都必须明确检查并发机制是否完好，并在修改后验证处理时间。`maxWorkers` 参数应作为可观测的配置项暴露给用户。
